{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msHf0xgt_Nws",
    "tags": []
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1636606637681,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "9EmiWYWXAHFA"
   },
   "outputs": [],
   "source": [
    "# For Changing Python interpreter on Google Collabe only - Doesn't work anyway\n",
    "# !update-alternatives --install /usr/bin/python python /usr/bin/python3.9 1\n",
    "# !update-alternatives --list python\n",
    "# !update-alternatives --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9064,
     "status": "ok",
     "timestamp": 1636606647221,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "XlJEwAkiJkdB",
    "outputId": "978f2026-e40b-4a85-af31-ebaea313be7f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: category-encoders in ./.local/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: nlpaug in ./.local/lib/python3.8/site-packages (1.1.8)\n",
      "Requirement already satisfied: ujson in ./.local/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: wordcloud in ./.local/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: tensorflow-addons in ./.local/lib/python3.8/site-packages (0.15.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category-encoders) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in ./.local/lib/python3.8/site-packages (from category-encoders) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.21.1 in ./.local/lib/python3.8/site-packages (from category-encoders) (1.3.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in ./.local/lib/python3.8/site-packages (from category-encoders) (0.13.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in ./.local/lib/python3.8/site-packages (from category-encoders) (0.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/lib/python3/dist-packages (from category-encoders) (0.22.2.post1)\n",
      "Requirement already satisfied: sacremoses in ./.local/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./.local/lib/python3.8/site-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.8/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./.local/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./.local/lib/python3.8/site-packages (from datasets) (2021.11.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in ./.local/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from wordcloud) (7.0.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in ./.local/lib/python3.8/site-packages (from tensorflow-addons) (2.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.21.1->category-encoders) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=0.21.1->category-encoders) (2019.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.1->category-encoders) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib->wordcloud) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (1.21.4)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.8/site-packages (1.3.4)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
      "     |█████████████████████           | 322.5 MB 113.9 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████████████████| 489.6 MB 120.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/lib/python3/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/lib/python3/dist-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.11.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "     |████████████████████████████████| 2.1 MB 99.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.2)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 92.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.29.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.6.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "     |████████████████████████████████| 463 kB 94.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tensorboard~=2.6 in /usr/lib/python3/dist-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.4.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\n",
      "     |████████████████████████████████| 13.4 MB 92.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.2.1)\n",
      "Installing collected packages: tensorflow-io-gcs-filesystem, tensorflow-estimator, libclang, keras, tensorflow\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed keras-2.7.0 libclang-12.0.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0\n"
     ]
    }
   ],
   "source": [
    "# For lambda cloud\n",
    "# !pip install pandas numpy  --upgrade\n",
    "!pip install category-encoders transformers datasets nlpaug ujson wordcloud tensorflow-addons\n",
    "!pip install --upgrade numpy pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31367,
     "status": "ok",
     "timestamp": 1636606678571,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "MXfrBb3TA130",
    "outputId": "a8ad35db-c224-412d-86fa-7ec7465595eb",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete 2021-11-19 08:32:31.205328\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from typing import Tuple, FrozenSet, List\n",
    "\n",
    "from category_encoders import BinaryEncoder, OneHotEncoder\n",
    "\n",
    "# from datasets import Dataset\n",
    "import ujson\n",
    "from tqdm import tqdm\n",
    "# from wordcloud import WordCloud\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "import nlpaug.flow as naf\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# from textaugment import Word2vec\n",
    "# import gensim.downloader as downloader\n",
    "import datetime\n",
    "print(f\"Import complete {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1636606746024,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "QxcDk2VeANuI"
   },
   "outputs": [],
   "source": [
    "def reduce_subclasses(annotated_texts: pd.DataFrame, verbose: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"Reduce number of classes by merging homogenous(no conflicting) subcategories of main classes.\"\"\"\n",
    "    n_classes = len(annotated_texts['label'].unique())\n",
    "    data_size = len(annotated_texts)\n",
    "    # codes whose subcategories are so similar that they can be disregarded\n",
    "    homogenous_categories = ['601', '602', '606', '607', '201', '416', '608', '103']\n",
    "\n",
    "    category_prefixes = annotated_texts['label'].str.extract(r'(\\d+)\\..', expand=False)\n",
    "    annotated_texts['label'] = np.where(\n",
    "        category_prefixes.isin(homogenous_categories),\n",
    "        category_prefixes,\n",
    "        annotated_texts['label']\n",
    "    )\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f\"Merged subcategories for {homogenous_categories}\\n\"\n",
    "              f\"Number of classes: {n_classes} -> {len(annotated_texts['label'].unique())}\\n\"\n",
    "              f\"Data size: {data_size} -> {len(annotated_texts)}\")\n",
    "\n",
    "    return annotated_texts\n",
    "\n",
    "\n",
    "def keep_top_k_classes(annotated_texts: pd.DataFrame, k: int, plus: List[str] = None, other: str = None,\n",
    "                       verbose: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep only top k most frequent classes plus specified classes, the rest are changed to a specific class.\n",
    "\n",
    "    :param annotated_texts:\n",
    "    :param k: top k classes to keep\n",
    "    :param plus: also keep these classes\n",
    "    :param other: change the rest into this class\n",
    "    :param verbose: set to 1 to show more info\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_classes = len(annotated_texts['label'].unique())\n",
    "    if plus is None:\n",
    "        plus = []\n",
    "    top_classes = [class_ for class_ in annotated_texts['label'].value_counts().index if class_ not in plus][:k] + plus\n",
    "    annotated_texts['label'] = np.where(annotated_texts['label'].isin(top_classes), annotated_texts['label'], other)\n",
    "\n",
    "    if verbose > 0:\n",
    "        additional = f'Plus {plus}.' if plus else ''\n",
    "        print(f\"Kept top {k} classes: {top_classes}. {additional} Set {n_classes} others to {other}\")\n",
    "\n",
    "    return annotated_texts\n",
    "\n",
    "\n",
    "def random_undersample(annotated_texts: pd.DataFrame, random_state: int = None, verbose: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"Random under sample all majority classes\"\"\"\n",
    "    distribution = annotated_texts['label'].value_counts().describe()\n",
    "    if verbose > 0:\n",
    "        print(f\"Under-sampling to {distribution['min']} samples per class.\")\n",
    "    return annotated_texts.groupby('label').sample(n=int(distribution['min']), random_state=random_state)\n",
    "\n",
    "\n",
    "def augment(annotated_texts: pd.DataFrame, batch_size: int = 32, max_length: int = 512, device: str = 'cpu',\n",
    "            verbose: int = 0, drop_original: bool = False) -> pd.DataFrame:\n",
    "    \"\"\" Performs text augmentation\n",
    "\n",
    "    :param annotated_texts: training data\n",
    "    :param batch_size:\n",
    "    :param max_length:\n",
    "    :param device: 'cpu' or 'cuda'\n",
    "    :param verbose:\n",
    "    :param drop_original: set to True to return only augmented data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # pipe = naf.Sequential([\n",
    "    #     naw.BackTranslationAug(max_length=max_length, batch_size=batch_size, verbose=verbose,\n",
    "    #                                             device=device),\n",
    "    #     # naw.ContextualWordEmbsAug(model_path='bert-base-cased', action=\"insert\", batch_size=batch_size,\n",
    "    #     #                           verbose=verbose, device='cuda'),\n",
    "    #     naw.split.SplitAug(aug_p=0.3, min_char=2, verbose=verbose)\n",
    "    # ])\n",
    "\n",
    "    # Truncate\n",
    "    augmented_texts = annotated_texts.copy()\n",
    "    augmented_texts['text'] = np.where(augmented_texts['text'].str.len() > max_length,\n",
    "                                       augmented_texts['text'].str[:max_length],\n",
    "                                       augmented_texts['text'])\n",
    "    # keep texts with at least two valid tokens\n",
    "    augmented_texts = augmented_texts[augmented_texts['text'].str.contains(r'[a-zA-Z0-9]{2,}')]\n",
    "\n",
    "    # Augment\n",
    "    pipe = naf.Sequential([\n",
    "        naf.Sometimes([\n",
    "            naw.ContextualWordEmbsAug(aug_p=0.3, model_path='bert-base-cased', action=\"insert\",\n",
    "                                      batch_size=batch_size, verbose=verbose, device=device),\n",
    "            naw.ContextualWordEmbsAug(aug_p=0.3, model_path='bert-base-cased', action=\"substitute\",\n",
    "                                      batch_size=batch_size, verbose=verbose, device=device),\n",
    "        ]),\n",
    "        # naw.SynonymAug(aug_p=0.3, verbose=verbose),\n",
    "        naw.SplitAug(aug_p=0.1, verbose=verbose)\n",
    "    ])\n",
    "    pipe.device = device\n",
    "    augmented_texts['text'] = pipe.augment(augmented_texts['text'].to_list())\n",
    "\n",
    "    if drop_original:\n",
    "        return augmented_texts\n",
    "    else:\n",
    "        return pd.concat([annotated_texts, augmented_texts], axis=0)\n",
    "    # augmenters = [\n",
    "    #     naw.ContextualWordEmbsAug(aug_p=0.3, model_path='bert-base-cased', action=\"insert\",\n",
    "    #                               batch_size=batch_size, verbose=verbose, device='cuda'),\n",
    "    #     naw.ContextualWordEmbsAug(aug_p=0.3, model_path='bert-base-cased', action=\"substitution\",\n",
    "    #                               batch_size=batch_size, verbose=verbose, device='cuda'),\n",
    "    #     naw.split.SplitAug(aug_p=0.3, min_char=2, verbose=verbose)\n",
    "    # ]\n",
    "    # results = []\n",
    "    # for augmenter in augmenters:\n",
    "    #     result = augmented_texts.copy()\n",
    "    #     result['text'] = augmenter.augment(result['text'].to_list())\n",
    "    #     result['text'].str.replace(r\"\\s'\\s\", \"'\", regex=True)\n",
    "    #     results.append(result)\n",
    "\n",
    "    # # Merge append augmented data\n",
    "    # augmented_texts = pd.concat([augmented_texts] + results, ignore_index=True)\n",
    "    #\n",
    "    # if verbose >= 1:\n",
    "    #     i = 0\n",
    "    #     for pre, post in zip(augmented_texts['text'], results[0]['text']):\n",
    "    #         print('pre:\\n' + pre)\n",
    "    #         print('post:\\n' + post)\n",
    "    #         i += 1\n",
    "    #         if i >= 5:\n",
    "    #             break\n",
    "    #\n",
    "    # return augmented_texts\n",
    "\n",
    "    # augmentation ideas\n",
    "    # cannot use sentence level augmentations we only have quasi-sentences by themselves\n",
    "    # contextual embedding substitution, insertion\n",
    "    # minimal to no random shuffling - it can change the meaning of a sentence\n",
    "    # decent amount of word splitting - may be a frequent occurrence in scraped text\n",
    "    # speech style transformations (formal to casual to very casual)\n",
    "    # insertion of filler words (um, hum, like, i think, yeah, i mean, well, look)\n",
    "    # abstract summarization - maybe only for examples that are too long\n",
    "    # use reserved for phrase-to-phrase and phrase-to-word and word-to-phrase replacement -- use websites that do this\n",
    "    # use augmentation to address class imbalance (augment minority classes first)\n",
    "    # use an augmentation pipeline\n",
    "\n",
    "\n",
    "# def augment_book_review_data(reviews: pd.DataFrame, batch_size: int = 32, max_length: int = 512, device: str = 'cpu',\n",
    "#                              drop_original: bool = False, verbose: int = 0) -> pd.DataFrame:\n",
    "#     # regularised_substitutes = {\n",
    "#     #     'book': {'item', 'policy', 'idea', 'notion', 'undertaking', 'trip', 'experience', 'system'},\n",
    "#     #     'read': {'support', 'change', 'review'},\n",
    "#     #     'character': {'person', 'candidate', 'case', 'areas'},\n",
    "#     #     'story': {'proposal', 'plan', 'picture', 'narrative'},\n",
    "#     #     'author': {'entity', 'writer', 'speaker', 'person', 'company', 'people'},\n",
    "#     # }\n",
    "#     # all_reserved_tokens: List[List[str]] = [[k] + list(v) for k, v in regularised_substitutes.items()]\n",
    "#     # all_reserved_tokens += [[e.capitalize() for e in tokens] for tokens in all_reserved_tokens]\n",
    "#     # pipe = naf.Sequential([naw.ReservedAug(all_reserved_tokens)])\n",
    "#     #\n",
    "#     # augmented_reviews = reviews.copy()\n",
    "#     # augmented_reviews['text'] = pipe.augment(reviews['text'].to_list())\n",
    "#     # model = downloader.load('word2vec-google-news-300')\n",
    "#     # aug_w2v = naw.WordEmbsAug(\n",
    "#     #     model_type='word2vec',\n",
    "#     #     # model_path='./GoogleNews-vectors-negative300.bin',\n",
    "#     #     model=model,\n",
    "#     #     action=\"substitute\"\n",
    "#     # )\n",
    "\n",
    "#     reviews = reviews.copy()\n",
    "#     reviews['text'] = np.where(reviews['text'].str.len() > max_length, reviews['text'].str[:max_length],\n",
    "#                                reviews['text'])\n",
    "#     # keep texts with at least two valid tokens\n",
    "#     augmented_reviews = reviews[reviews['text'].str.contains(r'[a-zA-Z0-9]{2,}')]\n",
    "\n",
    "#     aug_contextual = naw.ContextualWordEmbsAug(model_path='distilbert-base-cased', action='substitute', aug_p=0.5,\n",
    "#                                                batch_size=batch_size, verbose=verbose, device=device)\n",
    "#     augmented_reviews['text'] = aug_contextual.augment(reviews['text'].to_list())\n",
    "#     augmented_reviews['text'] = augmented_reviews['text'].str.replace(r\"\\s'\\s\", \"'\", regex=True)\n",
    "\n",
    "#     # Download Google Word2vec embeddings\n",
    "#     # model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "#     # t = Word2vec(model=model)\n",
    "#     # augmented_reviews = reviews.copy()\n",
    "#     # augmented_reviews['text'] = [t.augment(text) for text in augmented_reviews['text']]\n",
    "#     # augmented_reviews['text'] = augmented_reviews['text'].str.replace(r\"\\s'\\s\", \"'\", regex=True)\n",
    "\n",
    "#     if drop_original:\n",
    "#         return augmented_reviews\n",
    "#     else:\n",
    "#         return pd.concat([reviews, augmented_reviews], axis=0)\n",
    "\n",
    "\n",
    "# def make_word_cloud(texts: str, filename: str = 'word-cloud.png') -> None:\n",
    "#     cloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue', width=800,\n",
    "#                       height=400)\n",
    "#     cloud.generate(texts)\n",
    "#     cloud.to_image()\n",
    "#     cloud.to_file(filename)\n",
    "\n",
    "\n",
    "def load_data(countries: FrozenSet[str] = frozenset({'AU', 'CA', 'IE', 'IL', 'NZ', 'SA', 'UK', 'US'}),\n",
    "              return_raw=False, data_dir=os.path.join('..', 'datasets', 'MARPOR', 'Annotated text')) -> pd.DataFrame:\n",
    "    \"\"\"Load annotated text data from disk and performs basic preprocessing.\"\"\"\n",
    "\n",
    "    def read_and_tag_csv(path, country):\n",
    "        df = pd.read_csv(path)\n",
    "        df['country'] = country\n",
    "        return df\n",
    "\n",
    "    # Load annotated text from MARPOR corpus\n",
    "    country_data_dirs = {country: os.path.join(data_dir, f'{country} 2001-2021')\n",
    "                         for country in countries}\n",
    "    annotated_texts_data = [\n",
    "        read_and_tag_csv(full_path, country)\n",
    "        for country, directory in country_data_dirs.items()\n",
    "        for filename in os.listdir(directory)\n",
    "        if os.path.isfile(full_path := os.path.join(directory, filename))\n",
    "    ]\n",
    "    annotated_texts = pd.concat(annotated_texts_data, axis=0, ignore_index=True)\n",
    "\n",
    "    if return_raw:\n",
    "        # Return dataframe without basic preprocessing\n",
    "        return annotated_texts\n",
    "\n",
    "    # Basic preprocessing\n",
    "    annotated_texts = (\n",
    "        annotated_texts.rename(columns={'cmp_code': 'label'})\n",
    "        .drop(columns=['eu_code'])\n",
    "    )\n",
    "    annotated_texts = annotated_texts[annotated_texts['label'] != 'H']  # drop headings\n",
    "    annotated_texts['label'] = (\n",
    "        annotated_texts['label'].astype(str)\n",
    "        .str.replace('.0', '', regex=False)  # remove redundant suffix\n",
    "        .str.replace(r'^0$', '000', regex=True)  # political statements without clear category\n",
    "        .str.replace('nan', 'N/A', regex=False)  # non-political statements\n",
    "    )\n",
    "    annotated_texts['text'] = annotated_texts['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "\n",
    "    return annotated_texts\n",
    "\n",
    "\n",
    "def load_annotated_book_reviews(file_path=os.path.join('..', 'datasets', 'non-political-texts',\n",
    "                                                       'goodreads_reviews_spoiler.json')) -> pd.DataFrame:\n",
    "    \"\"\"Load goodreads spoilers book review data in appropriate format for classifier.\"\"\"\n",
    "    # Load data\n",
    "    with open(file_path, 'r') as f:\n",
    "        reviews = [ujson.loads(line.rstrip()) for line in tqdm(f)]  # loads as dict from some reason\n",
    "    reviews = pd.DataFrame.from_records(reviews)\n",
    "\n",
    "    # Transform to conform to input format\n",
    "    reviews = reviews.rename(columns={'review_sentences': 'text'})\n",
    "    reviews = reviews[['text']].explode('text')\n",
    "    reviews['text'] = reviews['text'].str[1]\n",
    "    reviews['label'] = 'N/A'\n",
    "\n",
    "    # Basic preprocessing\n",
    "    reviews = reviews.dropna(subset=['text', 'label'], how='any')\n",
    "    reviews['text'] = reviews['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "\n",
    "    return reviews[['text', 'label']]\n",
    "\n",
    "\n",
    "def inject_book_reviews(reviews: pd.DataFrame, annotated_texts: pd.DataFrame, multiplier: float = 1.0) -> pd.DataFrame:\n",
    "    \"\"\"Add book review data as N/A labelled rows.\"\"\"\n",
    "    current_size = len(annotated_texts[annotated_texts['label'] == 'N/A'])\n",
    "    injection_size = min(len(reviews), int(multiplier * current_size))\n",
    "    injection_df = reviews.sample(injection_size)\n",
    "    return pd.concat([annotated_texts, injection_df], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "def f1_macro(y_true, y_pred):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "def tokenize(examples, tokenizer):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "\n",
    "# def ds_to_tf_ds(dataset: Dataset, shuffle: bool = False, batch_size: int = 32,\n",
    "#                 target_name: str = 'label', features=None) -> tf.data.Dataset:\n",
    "#     \"\"\"Convert huggingFace Dataset into Tensorflow Dataset\"\"\"\n",
    "#     # Remove text column which should have already been used by the tokenizer and is now redundant\n",
    "#     dataset = dataset.remove_columns(['text']).with_format('tensorflow')  # can we keep text column?\n",
    "#     features = {x: dataset[x] for x in features}\n",
    "#     tf_dataset = tf.data.Dataset.from_tensor_slices((features, dataset[target_name]))\n",
    "#     if shuffle:\n",
    "#         tf_dataset = tf_dataset.shuffle(buffer_size=len(dataset))\n",
    "#     tf_dataset = tf_dataset.batch(batch_size)\n",
    "#     return tf_dataset\n",
    "\n",
    "\n",
    "# def df_to_dataset(dataframe: pd.Dataframe, shuffle=False, batch_size=32) -> tf.data.Dataset:\n",
    "#     \"\"\"A utility method to create a tf.data dataset from a Pandas Dataframe\"\"\"\n",
    "#     dataframe = dataframe.copy()\n",
    "#     labels = dataframe.pop('label')\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "#     if shuffle:\n",
    "#         ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "#     ds = ds.batch(batch_size)\n",
    "#     return ds\n",
    "\n",
    "\n",
    "def train_eval(X_train, y_train, X_val, y_val, X_test, y_test, pretrained_model: str, num_classes: int,\n",
    "               max_length: int = 512):\n",
    "    # Create folders to store results\n",
    "    model_dir = os.path.join('fine-tuned-models', pretrained_model.replace('/', '-'))\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Load Model and Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=num_classes)\n",
    "\n",
    "    # Reduce max input token count to save memory at the cost of accuracy\n",
    "    tokenizer.model_max_length = max_length\n",
    "    # default to right padding for model with absolute position embeddings\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    # Add special tokens\n",
    "    # special_tokens_dict = {'bos_token': '[BOS]', 'eos_token': '[EOS]', 'pad_token': '[PAD]'}\n",
    "    # tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    # tokenizer.pad_token = tokenizer.eos_token\n",
    "    # model.resize_token_embeddings(len(tokenizer))\n",
    "    # # fix model padding token id\n",
    "    # model.config.pad_token_id = tokenizer.pad_token\n",
    "\n",
    "    # Convert to huggingface Dataset\n",
    "    # train_ds = Dataset.from_pandas(train_df)\n",
    "    # val_ds = Dataset.from_pandas(val_df)\n",
    "    # test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "    # Tokenize data\n",
    "    # train_ds = train_ds.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    # val_ds = val_ds.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    # test_ds = test_ds.map(lambda x: tokenize(x, tokenizer), batched=True)\n",
    "    X_train = tokenizer(X_train['text'].to_list(), padding='max_length', truncation=True, return_tensors='tf').data\n",
    "    X_val = tokenizer(X_val['text'].to_list(), padding='max_length', truncation=True, return_tensors='tf').data\n",
    "    X_test = tokenizer(X_test['text'].to_list(), padding='max_length', truncation=True, return_tensors='tf').data\n",
    "\n",
    "    # Convert to Tensorflow Datasets\n",
    "    # batch_size = 8\n",
    "    # train_ds = ds_to_tf_ds(train_ds, shuffle=True, batch_size=batch_size, features=tokenizer.model_input_names)\n",
    "    # val_ds = ds_to_tf_ds(val_ds, batch_size=batch_size, features=tokenizer.model_input_names)\n",
    "    # test_ds = ds_to_tf_ds(test_ds, batch_size=batch_size, features=tokenizer.model_input_names)\n",
    "\n",
    "    # Use mixed precision to save memory\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "    # Train classifier, evaluate and save results\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['categorical_accuracy', tfa.metrics.F1Score(num_classes=num_classes, average='macro')],\n",
    "    )\n",
    "    # error when using f1_marco\n",
    "    model.summary()\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=1,\n",
    "                                                      restore_best_weights=True)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"training_1/cp.ckpt\", save_weights_only=True, verbose=1)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=15,\n",
    "                        callbacks=[early_stopping, cp_callback])\n",
    "    model.save(model_dir)\n",
    "    # model = tf.keras.models.load_model(os.path.join('fine-tuned-models', 'from-gpu-cloud', 'distilroberta-base',\n",
    "    #                                                 'tf_model.h5'))\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "\n",
    "    with open(os.path.join(model_dir, 'train-history.joblib'), 'wb') as logs_file, \\\n",
    "            open(os.path.join(model_dir, 'scores.joblib'), 'wb') as scores_file:\n",
    "        dump(scores, scores_file)\n",
    "        try:\n",
    "            print(history)\n",
    "            dump(history, logs_file)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1636606746024,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "QxcDk2VeANuI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotated_texts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OUR VISION AND PLAN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa has begun a new and far-reaching ...</td>\n",
       "      <td>202</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For more than a century, the ANC has led our p...</td>\n",
       "      <td>503</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That vision, inscribed in the Freedom Charter,...</td>\n",
       "      <td>202</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That vision became the soul of our constitutio...</td>\n",
       "      <td>202</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label country\n",
       "0                                OUR VISION AND PLAN   N/A      SA\n",
       "1  South Africa has begun a new and far-reaching ...   202      SA\n",
       "2  For more than a century, the ANC has led our p...   503      SA\n",
       "3  That vision, inscribed in the Freedom Charter,...   202      SA\n",
       "4  That vision became the soul of our constitutio...   202      SA"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_texts = load_data(data_dir=os.path.join('datasets', 'MARPOR', 'Annotated text'))\n",
    "print(\"annotated_texts\")\n",
    "annotated_texts.head()\n",
    "annotated_texts_ = annotated_texts.copy(deep=True)\n",
    "# annotated_texts = annotated_texts_.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1636606746024,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "QxcDk2VeANuI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1378033it [00:46, 29680.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a special book.</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It started slow for about the first third, the...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is what I love about good science fiction...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is a 2015 Hugo winner, and translated from ...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For instance the intermixing of Chinese revolu...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0                            This is a special book.   N/A\n",
       "0  It started slow for about the first third, the...   N/A\n",
       "0  This is what I love about good science fiction...   N/A\n",
       "0  It is a 2015 Hugo winner, and translated from ...   N/A\n",
       "0  For instance the intermixing of Chinese revolu...   N/A"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = load_annotated_book_reviews(file_path=os.path.join('datasets', 'non-political-texts', 'goodreads_reviews_spoiler.json'))\n",
    "print(\"reviews\")\n",
    "reviews.head()\n",
    "reviews_ = reviews.copy(deep=True)\n",
    "# reviews = reviews_.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  124055040 \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  607510    \n",
      "=================================================================\n",
      "Total params: 124,662,550\n",
      "Trainable params: 124,662,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1014/1014 [==============================] - 1089s 1s/step - loss: 1.5938 - categorical_accuracy: 0.5459 - f1_score: 0.5364 - val_loss: 1.4210 - val_categorical_accuracy: 0.5880 - val_f1_score: 0.5800\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/15\n",
      "1014/1014 [==============================] - 1074s 1s/step - loss: 1.0553 - categorical_accuracy: 0.6893 - f1_score: 0.6844 - val_loss: 1.4622 - val_categorical_accuracy: 0.6001 - val_f1_score: 0.5922\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, dense_layer_call_fn while saving (showing 5 of 1060). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine-tuned-models/roberta-base/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine-tuned-models/roberta-base/assets\n",
      "/usr/lib/python3/dist-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 53s 153ms/step - loss: 1.4189 - categorical_accuracy: 0.5859 - f1_score: 0.5789\n",
      "<keras.callbacks.History object at 0x7f11656db340>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  81527808  \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  607510    \n",
      "=================================================================\n",
      "Total params: 82,135,318\n",
      "Trainable params: 82,135,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1014/1014 [==============================] - 563s 548ms/step - loss: 1.6015 - categorical_accuracy: 0.5385 - f1_score: 0.5290 - val_loss: 1.4208 - val_categorical_accuracy: 0.5856 - val_f1_score: 0.5773\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/15\n",
      "1014/1014 [==============================] - 556s 548ms/step - loss: 1.0871 - categorical_accuracy: 0.6790 - f1_score: 0.6736 - val_loss: 1.4626 - val_categorical_accuracy: 0.5921 - val_f1_score: 0.5839\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, dense_layer_call_fn while saving (showing 5 of 550). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine-tuned-models/distilroberta-base/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fine-tuned-models/distilroberta-base/assets\n",
      "/usr/lib/python3/dist-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 28s 79ms/step - loss: 1.4160 - categorical_accuracy: 0.5829 - f1_score: 0.5744\n",
      "<keras.callbacks.History object at 0x7f1169c4a430>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some layers of TFAlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_albert_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "albert (TFAlbertMainLayer)   multiple                  17683968  \n",
      "_________________________________________________________________\n",
      "dropout_876 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  22550     \n",
      "=================================================================\n",
      "Total params: 17,706,518\n",
      "Trainable params: 17,706,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " failed to allocate memory\n\t [[node tf_albert_for_sequence_classification_4/albert/encoder/albert_layer_groups_._0/albert_layers_._0/full_layer_layer_norm/batchnorm_15/mul_1 (defined at /home/ubuntu/.local/lib/python3.8/site-packages/transformers/models/albert/modeling_tf_albert.py:332) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_812503]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-8c407b0f17d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mpretrained_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distilroberta-base'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'albert-large-v2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xlnet-base-cased'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpretrained_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     train_eval(X_train, y_train, X_val, y_val, X_test, y_test, pretrained_model, num_classes=num_classes,\n\u001b[0m\u001b[1;32m     59\u001b[0m                max_length=max_length)\n",
      "\u001b[0;32m<ipython-input-59-50e697403316>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, pretrained_model, num_classes, max_length)\u001b[0m\n\u001b[1;32m    375\u001b[0m                                                       restore_best_weights=True)\n\u001b[1;32m    376\u001b[0m     \u001b[0mcp_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training_1/cp.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=15,\n\u001b[0m\u001b[1;32m    378\u001b[0m                         callbacks=[early_stopping, cp_callback])\n\u001b[1;32m    379\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node tf_albert_for_sequence_classification_4/albert/encoder/albert_layer_groups_._0/albert_layers_._0/full_layer_layer_norm/batchnorm_15/mul_1 (defined at /home/ubuntu/.local/lib/python3.8/site-packages/transformers/models/albert/modeling_tf_albert.py:332) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_812503]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "max_length = 512  # set max_length to 512 if gpu has more memory else set to 256\n",
    "\n",
    "try:\n",
    "    # Load cached data\n",
    "    X_train = pd.read_csv(os.path.join('cache', 'X_train.csv'), index_col=None).fillna('')\n",
    "    y_train = pd.read_csv(os.path.join('cache', 'y_train.csv'), index_col=None).fillna('')\n",
    "    X_val = pd.read_csv(os.path.join('cache', 'X_val.csv'), index_col=None).fillna('')\n",
    "    y_val = pd.read_csv(os.path.join('cache', 'y_val.csv'), index_col=None).fillna('')\n",
    "    X_test = pd.read_csv(os.path.join('cache', 'X_test.csv'), index_col=None).fillna('')\n",
    "    y_test = pd.read_csv(os.path.join('cache', 'y_test.csv'), index_col=None).fillna('')\n",
    "\n",
    "    num_classes = len(y_train['label'].unique())\n",
    "\n",
    "except (FileNotFoundError, EOFError):\n",
    "    annotated_texts = annotated_texts.dropna(how='any')\n",
    "    annotated_texts = inject_book_reviews(reviews, annotated_texts)\n",
    "    annotated_texts = reduce_subclasses(annotated_texts, verbose=1)\n",
    "    annotated_texts = keep_top_k_classes(annotated_texts, k=20, plus=['N/A'], other='000', verbose=1)\n",
    "    annotated_texts = random_undersample(annotated_texts, random_state=1, verbose=1)\n",
    "\n",
    "    num_classes = len(annotated_texts['label'].unique())\n",
    "\n",
    "    # Split dataframe into train, validation and test, 6:2:2\n",
    "    y, X = annotated_texts[['label']], annotated_texts.drop(columns=['label'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=1, test_size=0.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "    print(len(X_train), 'train examples')\n",
    "    print(len(X_val), 'validation examples')\n",
    "    print(len(X_test), 'test examples')\n",
    "\n",
    "    # Augment text\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    train_df = augment(train_df, batch_size=4096, max_length=max_length, device='cuda', verbose=1)\n",
    "    y_train, X_train = train_df[['label']], train_df.drop(columns=['label'])\n",
    "    assert len(X_train) == len(y_train)\n",
    "\n",
    "    # Cache preprocessed data\n",
    "    cache_dir = os.path.join('cache')\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    X_train.to_csv(os.path.join(cache_dir, 'X_train.csv'), index=False)\n",
    "    y_train.to_csv(os.path.join(cache_dir, 'y_train.csv'), index=False)\n",
    "    X_val.to_csv(os.path.join(cache_dir, 'X_val.csv'), index=False)\n",
    "    y_val.to_csv(os.path.join(cache_dir, 'y_val.csv'), index=False)\n",
    "    X_test.to_csv(os.path.join(cache_dir, 'X_test.csv'), index=False)\n",
    "    y_test.to_csv(os.path.join(cache_dir, 'y_test.csv'), index=False)\n",
    "\n",
    "# Encode label\n",
    "# label_encoder = BinaryEncoder()\n",
    "label_encoder = OneHotEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# cached: EleutherAI/gpt-neo-1.3B, EleutherAI/gpt-neo-2.7B, gpt2-medium, gpt2-large, bert-base-cased\n",
    "# 'distilroberta-base', 'roberta-base', 'xlnet-base-cased', 'albert-xlarge-v2',\n",
    "pretrained_models = ['roberta-base', 'distilroberta-base',  'albert-large-v2', 'xlnet-base-cased']\n",
    "for pretrained_model in pretrained_models:\n",
    "    train_eval(X_train, y_train, X_val, y_val, X_test, y_test, pretrained_model, num_classes=num_classes,\n",
    "               max_length=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 61104,
     "status": "ok",
     "timestamp": 1636606740580,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "nfCsaVGyBUrg"
   },
   "outputs": [],
   "source": [
    "# zip_dir(os.path.join('../datasets', 'MARPOR', 'Annotated text'))\n",
    "# zip_dir(os.path.join('../datasets', 'non-political-texts'))\n",
    "# unzip_dir('Annotated text.zip')\n",
    "# unzip_dir('non-political-texts.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603,
     "referenced_widgets": [
      "b8a5fc96c88d47a6a9ec22d8c4866e1d",
      "84705ba8adb94ff7ae8367c77938d100",
      "ae14a9ec0a65403d81dd14c1b37bcaef",
      "c55606d760524e0f957c5102010ba5a7",
      "0db5fa8c56f34914af499dcb3b02a428",
      "63c7f9647d894daf8c15f352a8f91ff3",
      "7321a407238b458eabf7754a2b45689e",
      "43db50e363544cbd990a4f7a4d3d4f77",
      "a94814c7c89d4b9b86777940a5233a22",
      "3f73cb1d1fce4eadbfbea1d5be1f28b5",
      "ef87e231cc674cd48821eb39f81ab52c",
      "d9064ba84d6b47d5a0358a79e81d1bd1",
      "1487d53551d54006a01a408b96df8744",
      "4eada0b42ea643b9969203b0e7311bd5",
      "3aba721ac072495c9d63c3b8f7711be5",
      "1c2d47a14c3746b08b652fd8a0c368b3",
      "a2d9798f1c98440eb0aa2bd2b66ce18d",
      "91920f1f3b3845b68c0ecce64ec48786",
      "30283111afaf436b91f48761f8369b75",
      "2bda4ad881574be39680609460f24430",
      "1f56d93417c64524b2a77885e256b3b2",
      "f56ac8325a2b436b8b7043cd60015493",
      "a480dceb1feb44b6a602341632b8307d",
      "f07b0bc529c046259d906632d3e69f75",
      "5fb6676b997e418a8fd9c41bf06bbd6d",
      "17af83f05d844417bb932b8e269613c4",
      "54aa88173d3b403e962650e06b040767",
      "7901c7cdca7b493ea348535f157098d1",
      "f73d8c002379471a9eb0a74e89216f6a",
      "9b0f192e185e46988fc4cfc182298e5d",
      "19fc28dceee646768b50061f39ab79fb",
      "6522b9eb84df4de7abb153a1d50a267a",
      "776cc8e5693443ef97a81e2e721ee54c",
      "e013bf2ce4684671abb596462a6778cd",
      "4d373830c5d742e79e16e4ab314780b1",
      "88db8fba33414b68a35c38bda4de785f",
      "91ffcde528ce4f35bf4398c9c8a35282",
      "37c6554e7e6b4e369dec60d13f027cb7",
      "461b93a333c445e1998c9266a643af29",
      "26a8fd36908b47e987fb645f523e365d",
      "096dd6bc68c843ea9750342c2d5a0415",
      "bf7553855e5b44e9b75d95c3ac434c51",
      "9d60ab02af6d4dcfba7f4456aace12df",
      "517ad1845bc040e2b728c6274554a503",
      "1f0d70302f304bb48eecbf07ee8554c9",
      "684bb7dee9fd4ce6a1a474bd8ad9ea3a",
      "a7f410c219eb4365a763146ded069613",
      "21f5c1ef3b6947549319b3d9f07a9f6d",
      "548aa12b84424d548692cf4a7da71161",
      "f2cad359ba9b4c33a7cc58bd4d4355b8",
      "3225ce28f176402986b21610717a99f7",
      "08a6eead0b1545db805daebcd1655410",
      "bb51402aea8c4d469d3007e78a29166d",
      "6b7987bd6dc74bc9adc21170f09cfc2d",
      "ab193ece9e774f6198ba5cea46734d13"
     ]
    },
    "executionInfo": {
     "elapsed": 55306,
     "status": "error",
     "timestamp": 1636606822824,
     "user": {
      "displayName": "Zhehong Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02642505119444240999"
     },
     "user_tz": -660
    },
    "id": "7tP-mbEkBPVu",
    "outputId": "66d3a947-3570-4534-a497-885741c193d8"
   },
   "outputs": [],
   "source": [
    "# annotated_texts = annotated_texts_.copy(deep=True)\n",
    "# reviews = reviews_.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zip_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a83effa772ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzip_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'zip_dir' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPf9rXHewK7TGJQIOKlqchb",
   "collapsed_sections": [],
   "mount_file_id": "1dD2hKz1R2kRFpQCAihqDn-76LeyF37ZU",
   "name": "train_evl_aug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08a6eead0b1545db805daebcd1655410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "096dd6bc68c843ea9750342c2d5a0415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0db5fa8c56f34914af499dcb3b02a428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef87e231cc674cd48821eb39f81ab52c",
      "placeholder": "​",
      "style": "IPY_MODEL_3f73cb1d1fce4eadbfbea1d5be1f28b5",
      "value": " 570/570 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "1487d53551d54006a01a408b96df8744": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17af83f05d844417bb932b8e269613c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19fc28dceee646768b50061f39ab79fb",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b0f192e185e46988fc4cfc182298e5d",
      "value": 29
     }
    },
    "19fc28dceee646768b50061f39ab79fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c2d47a14c3746b08b652fd8a0c368b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f56ac8325a2b436b8b7043cd60015493",
      "placeholder": "​",
      "style": "IPY_MODEL_1f56d93417c64524b2a77885e256b3b2",
      "value": " 416M/416M [00:22&lt;00:00, 23.2MB/s]"
     }
    },
    "1f0d70302f304bb48eecbf07ee8554c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7f410c219eb4365a763146ded069613",
       "IPY_MODEL_21f5c1ef3b6947549319b3d9f07a9f6d",
       "IPY_MODEL_548aa12b84424d548692cf4a7da71161"
      ],
      "layout": "IPY_MODEL_684bb7dee9fd4ce6a1a474bd8ad9ea3a"
     }
    },
    "1f56d93417c64524b2a77885e256b3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21f5c1ef3b6947549319b3d9f07a9f6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb51402aea8c4d469d3007e78a29166d",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08a6eead0b1545db805daebcd1655410",
      "value": 435797
     }
    },
    "26a8fd36908b47e987fb645f523e365d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bda4ad881574be39680609460f24430": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30283111afaf436b91f48761f8369b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3225ce28f176402986b21610717a99f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37c6554e7e6b4e369dec60d13f027cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_517ad1845bc040e2b728c6274554a503",
      "placeholder": "​",
      "style": "IPY_MODEL_9d60ab02af6d4dcfba7f4456aace12df",
      "value": " 208k/208k [00:00&lt;00:00, 756kB/s]"
     }
    },
    "3aba721ac072495c9d63c3b8f7711be5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bda4ad881574be39680609460f24430",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30283111afaf436b91f48761f8369b75",
      "value": 435779157
     }
    },
    "3f73cb1d1fce4eadbfbea1d5be1f28b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43db50e363544cbd990a4f7a4d3d4f77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "461b93a333c445e1998c9266a643af29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d373830c5d742e79e16e4ab314780b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4eada0b42ea643b9969203b0e7311bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91920f1f3b3845b68c0ecce64ec48786",
      "placeholder": "​",
      "style": "IPY_MODEL_a2d9798f1c98440eb0aa2bd2b66ce18d",
      "value": "Downloading: 100%"
     }
    },
    "517ad1845bc040e2b728c6274554a503": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "548aa12b84424d548692cf4a7da71161": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab193ece9e774f6198ba5cea46734d13",
      "placeholder": "​",
      "style": "IPY_MODEL_6b7987bd6dc74bc9adc21170f09cfc2d",
      "value": " 426k/426k [00:00&lt;00:00, 678kB/s]"
     }
    },
    "54aa88173d3b403e962650e06b040767": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_776cc8e5693443ef97a81e2e721ee54c",
      "placeholder": "​",
      "style": "IPY_MODEL_6522b9eb84df4de7abb153a1d50a267a",
      "value": " 29.0/29.0 [00:00&lt;00:00, 638B/s]"
     }
    },
    "5fb6676b997e418a8fd9c41bf06bbd6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f73d8c002379471a9eb0a74e89216f6a",
      "placeholder": "​",
      "style": "IPY_MODEL_7901c7cdca7b493ea348535f157098d1",
      "value": "Downloading: 100%"
     }
    },
    "63c7f9647d894daf8c15f352a8f91ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6522b9eb84df4de7abb153a1d50a267a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "684bb7dee9fd4ce6a1a474bd8ad9ea3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b7987bd6dc74bc9adc21170f09cfc2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7321a407238b458eabf7754a2b45689e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "776cc8e5693443ef97a81e2e721ee54c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7901c7cdca7b493ea348535f157098d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84705ba8adb94ff7ae8367c77938d100": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88db8fba33414b68a35c38bda4de785f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26a8fd36908b47e987fb645f523e365d",
      "placeholder": "​",
      "style": "IPY_MODEL_461b93a333c445e1998c9266a643af29",
      "value": "Downloading: 100%"
     }
    },
    "91920f1f3b3845b68c0ecce64ec48786": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91ffcde528ce4f35bf4398c9c8a35282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf7553855e5b44e9b75d95c3ac434c51",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_096dd6bc68c843ea9750342c2d5a0415",
      "value": 213450
     }
    },
    "9b0f192e185e46988fc4cfc182298e5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d60ab02af6d4dcfba7f4456aace12df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2d9798f1c98440eb0aa2bd2b66ce18d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a480dceb1feb44b6a602341632b8307d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fb6676b997e418a8fd9c41bf06bbd6d",
       "IPY_MODEL_17af83f05d844417bb932b8e269613c4",
       "IPY_MODEL_54aa88173d3b403e962650e06b040767"
      ],
      "layout": "IPY_MODEL_f07b0bc529c046259d906632d3e69f75"
     }
    },
    "a7f410c219eb4365a763146ded069613": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3225ce28f176402986b21610717a99f7",
      "placeholder": "​",
      "style": "IPY_MODEL_f2cad359ba9b4c33a7cc58bd4d4355b8",
      "value": "Downloading: 100%"
     }
    },
    "a94814c7c89d4b9b86777940a5233a22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab193ece9e774f6198ba5cea46734d13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae14a9ec0a65403d81dd14c1b37bcaef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7321a407238b458eabf7754a2b45689e",
      "placeholder": "​",
      "style": "IPY_MODEL_63c7f9647d894daf8c15f352a8f91ff3",
      "value": "Downloading: 100%"
     }
    },
    "b8a5fc96c88d47a6a9ec22d8c4866e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae14a9ec0a65403d81dd14c1b37bcaef",
       "IPY_MODEL_c55606d760524e0f957c5102010ba5a7",
       "IPY_MODEL_0db5fa8c56f34914af499dcb3b02a428"
      ],
      "layout": "IPY_MODEL_84705ba8adb94ff7ae8367c77938d100"
     }
    },
    "bb51402aea8c4d469d3007e78a29166d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf7553855e5b44e9b75d95c3ac434c51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c55606d760524e0f957c5102010ba5a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a94814c7c89d4b9b86777940a5233a22",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43db50e363544cbd990a4f7a4d3d4f77",
      "value": 570
     }
    },
    "d9064ba84d6b47d5a0358a79e81d1bd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4eada0b42ea643b9969203b0e7311bd5",
       "IPY_MODEL_3aba721ac072495c9d63c3b8f7711be5",
       "IPY_MODEL_1c2d47a14c3746b08b652fd8a0c368b3"
      ],
      "layout": "IPY_MODEL_1487d53551d54006a01a408b96df8744"
     }
    },
    "e013bf2ce4684671abb596462a6778cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88db8fba33414b68a35c38bda4de785f",
       "IPY_MODEL_91ffcde528ce4f35bf4398c9c8a35282",
       "IPY_MODEL_37c6554e7e6b4e369dec60d13f027cb7"
      ],
      "layout": "IPY_MODEL_4d373830c5d742e79e16e4ab314780b1"
     }
    },
    "ef87e231cc674cd48821eb39f81ab52c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f07b0bc529c046259d906632d3e69f75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2cad359ba9b4c33a7cc58bd4d4355b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f56ac8325a2b436b8b7043cd60015493": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f73d8c002379471a9eb0a74e89216f6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
